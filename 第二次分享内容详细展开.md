# 第二次分享内容详细展开
## 主题：从迭代到沉淀：智能文档助手的产品化之路

**时间：42分钟**  
**受众：产研团队**  
**视角：产品经理的心路历程和感想**

---

## 开场（3分钟）

### 自我介绍与主题
大家好。今天我主要从产品经理的角度，分享这个项目从0到1的心路历程。如果说第一次分享是"怎么做"，那今天就是"为什么这样做"，以及在这个过程中，我们遇到了什么问题，如何一步一步解决的，有哪些心得体会。

---

## 第一部分：产品诞生背景（5分钟）

### 1.1 客户场景
**核心问题：**
- 机构客户需要识别大量管理人的单据（交易确认单、分红确认单等），一般机构都有几十家管理人
- 不同管理人、不同业务类型的单据模板各异
- 传统方式需要每个客户、每个管理人、每个单据类型都要定制开发
- 周期长、维护难、复用性差，无法批量处理，效率低下
- 人工识别和录入成本高，容易出错，准确率难以保障

### 1.2 内部场景

**OX-产品开户/变更等：**
- 管理员信息识别
- 企业基本信息识别
- 反洗钱信息识别
- 产品基本信息识别
- 银行信息识别
- 受益人信息识别
- 经办人信息识别

---

## 第二部分：我们做了什么产品（5分钟）

### 2.1 产品介绍
我们做了一款**蜂鸟智能文档助手**（基于Dify平台的AI智能识别工具）。

**产品定位：**
- **通用场景的智能文档识别工具**：不仅面向机构客户，B端和C端客户都可以使用
- 支持多管理人、多业务类型的单据识别，也可以拓展到其他通用文档的识别
- 零代码配置，用户自主配置字段映射关系
- 适应不同客户类型的需求：机构客户的批量处理、B端客户的业务场景、C端客户的日常使用

### 2.2 核心能力
**技术方案：**
- 基于Dify平台的零代码方案
- PaddleOCR/MinerU + 本地大模型Deepseek R1/qwen-72b（协同长研团队集成）
- 本地化部署，避免数据外发
- 支持9种文件格式（PDF、DOC、DOCX、XLS、XLSX、PPT、PPTX、JPG、PNG）

**核心功能：**
- 深度学习OCR识别：自动识别单据内容
- 多模式选择：长/快思考双模式，适应不同场景
- 批量处理：支持批量并行处理
- 邮件通知：异步获取处理结果
- 零代码配置：用户自定义字段映射

### 2.3 产品成果
**数据验证：**
- 半年累计处理：约3000份文档
- **[预留位置：产品运行次数的截图]**

**识别准确率：**
  - 简单文档：98%
  - 复杂文档：94%
  - 整体平均：96.5%
- 性能指标：
  - 处理速度提升12倍
  - 单日处理能力提升10倍

**应用形式：**
- 蜂鸟SaaS平台
- 本地化部署（已成功在浙银理财落地）
- 标准API/MCP工具
- 网页版（手机号登录，即开即用） https://aifund.yingmi.com/#/chat/index

---

## 第三部分：产品功能演示（5分钟）

### 3.1 演示内容
（这部分可以根据实际情况进行演示，包括：）
- 产品界面展示
- 单据上传和识别流程
- 字段映射配置功能
- 识别结果展示
- 批量处理能力
- 不同模式的选择和效果对比

**[预留位置：产品演示视频]**

### 3.2 演示要点
- 展示产品的易用性和灵活性
- 体现识别准确率和处理效率
- 说明零代码配置的价值
- 演示不同场景下的应用效果

---

## 第四部分：心路历程（27分钟）

接下来我会按照时间线，分享每个阶段的用户需求、我们如何满足需求、遇到的问题、如何解决，以及心得体会。

### 4.1 第一阶段：从需求到想法验证（5分钟）

**用户的需求是什么：**
- 机构客户需要识别大量管理人的单据（交易确认单、分红确认单等）
- 希望降低人工识别和录入的成本，提升处理效率和准确率
- 传统定制开发方式成本高、周期长，希望能找到更高效的解决方案

**我们怎么满足用户的需求：**
- **第一步：发现Dify平台**
  - 公司正好在推广Dify平台
  - Dify提供了零代码搭建AI工作流的能力
  - 意识到这个平台可能适合快速验证AI识别方案

- **第二步：借助Dify初步验证想法**
  - 在Dify平台上搭建初步的工作流
  - 验证OCR + 大模型结合的技术可行性
  - 测试基本流程：上传文件 → OCR识别 → 大模型提取 → 输出结果
  - 用简单单据样本进行初步验证

- **第三步：借助Cursor跑通PaddleOCR效果**
  - 使用Cursor等AI编程工具实际编写和运行代码
  - 导入PaddleOCR库，配置识别参数
  - 用不同类型的单据样本测试识别效果
  - **对比测试**：
    - 传统OCR vs PaddleOCR的效果差异
    - 不同格式文件（JPG、PDF、扫描件）的识别准确率
    - 表格内容的识别准确度
  - 记录识别效果、准确率等关键指标

- **优化尝试：使用PaddleOCR坐标和置信度提升准确度**
  - 当时还没有集成MinerU，为了提升识别准确度，尝试利用PaddleOCR输出的坐标和置信度信息
  - 通过坐标信息定位文本位置，通过置信度筛选高质量识别结果
  - **测试发现**：
    - 在本地大模型（qwen-72b）的基础上，效果一般，提升不明显
    - 在云端更强模型的基础上，效果不错，能够有效提升识别准确率
  - 这个尝试帮助我们理解了不同模型能力对OCR后处理效果的影响，也为后续选择本地部署方案提供了参考

**遇到了什么问题：**
- **技术可行性的不确定性**：不确定AI能否准确理解单据结构，不知道OCR + 大模型结合是否可行
- **技术方案选择的困惑**：不知道哪种技术方案效果更好，如何验证和对比不同方案的效果差异

**如何解决的：**
- 通过Dify快速搭建demo，验证技术路线可行性
- 使用Cursor实际运行代码，对比测试不同方案
- 用真实单据样本进行验证，建立对技术能力的认知

**心得体会：**
1. **先做demo验证可行性**：产品经理的快速验证思维，避免大投入失败
2. **AI工具让验证成本大幅下降**：过去需要研发配合几周，现在产品经理可以独立验证
3. **多动手，多测试**：通过实际运行代码，建立对技术方案的直观认知

---

### 4.2 第二阶段：打造MVP（6分钟）

**用户的需求是什么：**
- 内部运营团队需要在实际业务场景中使用单据识别功能
- 需要支持不同管理人的各类单据，适应不同的单据模板
- 希望零代码配置，能够自主配置字段映射关系，降低使用门槛
- 既适用于内部使用场景，也适用于未来外部客户场景

**我们怎么满足用户的需求：**
- **第四步：收集需求打造MVP**
  - **需求收集**：
    - 与内部运营团队深入沟通，了解真实业务场景
    - 收集不同管理人的实际单据样本
    - 理解不同类型单据的识别难点和特殊要求
  - **MVP设计**：
    - 基于真实需求设计MVP功能清单
    - 确定核心功能：单据上传、字段识别、结果导出
    - 设计零代码配置方案，支持用户自定义字段映射
  - **MVP搭建**：
  - 在Dify平台上搭建完整工作流（完整Dify流程完全由产品经理侧搭建）
  - 协同长研团队集成PaddleOCR和本地大模型qwen-72b
  - 实现字段映射配置功能
- **格式验证结果**：
  - PDF格式（文本） → 识别准确 ✓
  - PDF格式（文本+表格） → 识别效果好 ✓
  - PDF格式（表格） → 表格识别准 ✓
  - 扫描件/图片格式（纯文本） → 识别准确 ✓
  - **图片格式的表格** → 效果一般 ⚠️
  - 原始单据（JPG换行场景） → 效果一般 ⚠️

**验证总结：** 文本和图片效果都可以，但涉及到图片格式的表格，效果就一般。这也是后来为什么要集成MinerU工具的原因之一。

**遇到了什么问题：**

**① 本地大模型效果的不确定性**
- 必须基于本地部署的大模型进行测试，但不确定本地模型的效果能否满足识别要求
- 不同管理人的单据模板差异大，不知道能否统一处理
- 不同业务类型的单据结构复杂，担心识别准确率不够
- 需要大量测试验证，但资源有限

**② 提示词设计缺乏经验**
- 不知道如何设计提示词才能让AI准确理解单据结构
- 不同单据模板的格式差异大，需要适配但缺乏统一的提示词模板
- 提示词效果难以量化评估，优化方向不明确

**③ 灵活性与易用性的平衡难题**
- 既需要支持用户自定义配置，又要保证易用性，两者如何平衡？
- 内部使用场景和外部客户场景需求不同，如何统一设计？
- 配置太复杂用户不会用，配置太简单又不够灵活

**④ 通用架构设计的挑战**
- 如何在Dify工作流中设计一个既能支持不同业务场景，又能兼容不同单据模板的通用架构？
- 既要保证可扩展性，又要考虑未来的可移植性，架构设计的复杂度如何控制？
- 如何在保持灵活性的同时，避免系统过于复杂难维护？

**如何解决的：**
- 逐步摸索Dify平台，从简单到复杂，从组件到代码
- **Dify平台使用的组件**：
  - **迭代组件**：用于多页文档的逐页处理
  - **代码组件**：实现复杂的逻辑处理和数据处理
  - **模板转换组件**：支持不同单据模板的结构化转换
  - 其他组件组合，构建完整的识别工作流
- 借助AI工具（如Cursor）帮助理解和调试
- 与蜂鸟研发、长研团队紧密协作，共同打磨功能
- 产品、研发、测试共同投入，大量测试不同单据样本，不断优化提示词和配置
- 在Dify工作流中设计通用架构，支持不同场景

**[预留位置：完整dify工作流的截图]**

**心得体会：**
- **产品经理可以深度参与技术实现**：这个产品后端的Dify流程完全由产品侧搭建，AI时代下产品经理的能力边界可以快速扩展
- **产研协作很重要**：虽然Dify流程由产品经理搭建，但技术组件的集成（如PaddleOCR、大模型等）需要协同研发团队完成

---

### 4.3 第三阶段：内部打磨（8分钟）

**用户的需求是什么：**
- **真实使用反馈**：内部运营团队在实际使用MVP版本后，提出了各种改进需求
- **准确率提升**：多页表格识别准确率不足，需要改进
- **场景兼容**：需要兼容更多不同的识别场景
- **体验优化**：等待焦虑，不知道处理进度；大批量处理时担心结果丢失

**我们怎么满足用户的需求：**
- **第五步：内部运营持续试用，持续打磨**
  - MVP版本先给内部运营团队使用
  - 收集真实使用反馈和问题
  - **打磨功能场景丰富度**：从单一场景扩展到多管理人、多业务类型
  - **打磨操作体验**：优化用户界面、流程体验、结果呈现
  - 基于反馈持续迭代优化（V1.0 → V1.5，6个版本迭代）

**产品功能迭代机制：**
除了用户主动反馈，还通过跟踪运行数据主动发现问题：
- 不定期查看后台日志，分析失败案例和原因
- 主动联系用户了解情况，获取失败样本进行测试
- 基于测试结果提出改进方案，持续迭代

这种方式能够更快速地响应和解决问题，而不是被动等待用户反馈。

**第一次迭代（V1.1）：**
- **用户需求**：多页表格识别准确率不足
- **解决方案**：引入迭代式并行处理
  - 逐页并行处理
  - 结果组装优化
- **效果**：多页表格识别准确率有所提升

**第二次迭代（V1.2）：**
- **用户需求**：需要兼容更多识别场景
- **解决方案**：引入双模式识别（协同长研团队完成）
  - 长思考模式：Deepseek R1本地大模型，复杂场景，准确但慢
  - 快思考模式：Qwen2.5-32b，简单场景，快速
- **亮点**：支持指定页码识别（例如："1-3, 5, 7-9"）
- **效果**：用户可根据场景选择最优模式

**第六步：集成到蜂鸟运营开户流程**
- 双模式上线后，立即集成到蜂鸟3.0运营开户流程
- 成为正式的业务工具，支撑日常运营工作

**[预留位置：嵌入运营开户流程的截图]**


**第三次迭代（V1.3）：**
- **用户需求**：
  - 等待焦虑，不知道处理进度
  - 识别结果如果没有及时保存就关闭了网页，尤其是在大批量文件识别的时候，容易丢失结果
- **解决方案**：
  - 新增进度条：可视化AI生成时间，解决等待焦虑
  - 新增邮件通知：异步获取结果，即使关闭网页也能通过邮件获取识别结果，避免大批量处理时结果丢失

**关键里程碑：协同长研集成MinerU（V1.4）**
- 协同长研团队成功集成MinerU工具
- **实现PDF版式识别能力**：解决了传统PaddleOCR对图片格式表格识别准确度不高的问题
- **支持复杂表格识别**：表格内容有换行也能完整识别
- **扩展文件格式支持**：新增doc格式支持
- **提升识别准确度**：特别是表格和版式复杂文档的识别效果有所改善


**遇到了什么问题：**

**① 准确率不足的问题**
- 用户反馈多页表格识别准确率不足，影响实际使用
- 某些格式（特别是图片格式表格）识别效果不佳

**② 场景兼容性的挑战**
- 用户希望兼容更多不同的识别场景
- 现有方案难以统一支持所有场景需求

**③ 用户体验的痛点**
- 用户等待处理时不知道进度，产生焦虑
- 大批量处理时，如果关闭网页会丢失结果，使用体验差

**④ 性能和效率优化的难题**
- 用户使用后反馈处理速度需要更快，但如何在保证不影响蜂鸟原有交易系统稳定性的同时提升速度？
- 如何找到最优的识别路径和流程，提升整体性能？

**如何解决的：**
- 基于用户反馈快速迭代
- 与研发团队协作优化技术方案
- 持续打磨功能和体验
- 集成MinerU等工具提升能力
- **优化处理效率**：
  - 优化识别流程，减少处理时间
  - 引入并行处理、批次处理等机制
- **优化识别路径**：
  - 探索最优的识别路径和流程
  - 尝试不同的技术组合方案
  - 找到准确率和效率的最佳平衡点
  - 形成标准化的识别流程

**心得体会：**
- **用户驱动**：所有改进都来自真实需求，不是闭门造车
- **小步快跑**：每次迭代解决一个核心问题，降低风险

---

### 4.4 第四阶段：产品化推广（8分钟）

**用户的需求是什么：**
- **访问权限受限的问题**：大部分金融机构没有蜂鸟系统权限，无法使用该产品；C端客户同样无法访问
- **更便捷的访问方式**：希望能够方便快捷地使用产品，无需复杂配置
- **数据安全保障**：金融机构客户需要本地化部署，确保数据不外泄
- **系统集成需求**：希望能够以标准API/MCP工具形式嵌入到现有系统中

**我们怎么满足用户的需求：**
- **第七步：发布手机验证即可登录的使用版本**
  - 开发独立访问版本，支持手机号登录
  - 降低使用门槛，方便快捷访问
  - 扩大产品覆盖范围，提升易用性
  - 网页版地址：https://aifund.yingmi.com/#/chat/index

  **[预留位置：网页版系统的截图]**

- **第八步：给浙银理财做本地化部署**
  - 产品成熟后，向外部客户推广
  - 浙银理财成功完成本地化部署
  - 所有数据和模型运行于客户私有环境
  - 实现最高级别的数据安全与合规管控

  **[预留位置：浙银理财本地化部署的系统界面]**

- **第九步：跑通对应的MCP调用**
  - 打造标准API/MCP工具
  - 支持以MCP工具形式嵌入其他系统
  - 实现AI能力的标准化输出和调用

  **[预留位置：MCP工具的截图]**

**遇到了什么问题：**
- AI产品始终有个绕不过去的问题，就是幻觉和准确性问题
- 在金融机构中，对交易、数据的准确度必须是100%，99.99%都不可接受

**如何解决的：**
- **技术层面**：通过调用更强的大模型，集成效果更好的OCR工具（如deepseek-OCR），提升识别准确率
- **产品功能层面**：支持识别结果可溯源（实施中），便于追溯和复核
- **业务流程层面**：在业务端增加复核环节，AI预处理 + 人工复核

---

## 总结与思考（2分钟）

### 一、产品化心得

**核心理念：**
- **需求驱动，而非技术驱动**：从客户需求出发，而非为了展示技术而做产品
- **小步快跑，持续迭代**：快速验证、持续打磨、逐步完善
- **体验优先，价值导向**：关注用户体验和实际业务价值

**产品化的完整路径：**
1. **快速验证**：MVP快速验证可行性，降低试错成本
2. **找到高频场景**：聚焦核心业务场景，解决真实痛点
3. **解决痛点问题**：针对高频场景的核心痛点，提供有效解决方案
4. **持续迭代打磨**：基于用户反馈持续优化，持续完善产品
5. **产品化复制推广**：将成熟方案标准化，支持机构客户本地部署

**推广实践：**
虽然需求来自客户，但产品推广采取了"内部打磨 → 客户落地"的路径：
- **MVP版本先给内部用**：先在公司内部使用，进行真实场景验证
- **持续打磨优化**：基于内部使用反馈，持续迭代完善（V1.0 → V1.5，6个版本迭代）
- **再向客户推广落地**：产品成熟后，再向客户推广，支持本地化部署
- **关键体会**：内部打磨降低风险，在可控环境下充分验证产品能力，降低客户落地风险

**产品演进路径：**
从工具到产品，从产品到平台——逐步完善功能、优化体验，形成标准化解决方案，最终打造为可复制的平台化能力

**用户驱动的正向循环：**
帮助用户解决问题 → 用户提效 → 想进一步提效 → 更多需求 → 持续迭代

---

### 二、AI时代的产品经理

**能力边界的快速扩展：**
- **AI时代产研边界正在消融**：产品向研发渗透，研发向产品靠近，AI大模型加速边界融合

**工具链的主动拥抱：**
- **验证成本急剧降低**：过去需要研发配合几周才能验证的想法，现在产品经理可以独立完成

**技术边界的理解与成本意识：**
- **多动手实践建立认知**：自己用Cursor跑PaddleOCR看效果差异，自己试用qwen模型和Deepseek模型，通过实际测试理解不同模型能力对效果的影响
- **借助AI理解代码**：不需要懂具体的代码细节，但借助AI工具能理解代码做的事情和步骤，知道工具能做什么、不能做什么
- **心中有成本概念**：通过实际搭建和测试，了解技术方案的边界、适用场景和成本，知道哪些场景可行、哪些不可行

**产品经理要多动手：**
- **跑demo、测效果**：AI时代，代码不是问题，产品经理可以多跑demo、测试效果，熟悉大模型能力边界
- **区分验证与工程**：难的是工程问题，工程问题交给研发团队；产品经理专注于验证想法、测试效果、理解边界

---

### 三、AI产品在金融领域的应用思考

**核心挑战：**
- 在金融机构中，对交易、数据的准确度必须是100%，99.99%都不可接受
- 必须严格筛选场景，不是所有场景都适合直接应用AI能力
- 需要思考如何在保证准确性的前提下，发挥AI的价值

**关键体会：场景选择很关键**——在金融领域，必须考虑准确性和复核机制，选择合适的应用场景

**场景细分的思考框架：**
在选择AI应用场景时需要深入细分：
1. **哪些场景可以集成AI**：准确率要求相对宽松，或者有容错机制的场景
2. **哪些场景不行**：对准确性要求极高，不允许任何误差的场景
3. **不行场景中的哪些环节可以集成**：即使整体场景不行，某些环节可能可以应用
4. **不行场景为什么不行**：明确技术边界和风险点
5. **能不能通过复核环节解决**：考虑增加人工复核环节，确保准确性
6. **复核成本是否可接受**：复核成本要低于原本场景的投入成本，才有应用价值

**以本项目为例：**
通过上述框架分析，我们选择的智能文档助手属于**可以增加复核环节**的场景：
- AI识别结果经过人工复核确认
- AI预处理 + 人工复核的成本，远低于传统完全人工处理的成本
- 通过复核机制，对AI结果承担责任，符合金融机构的合规要求
- 即使增加复核环节，整体效率仍高于纯人工方式

### 与第一次分享的呼应

- **第一次分享**：展示"怎么做"的技术实现
- **第二次分享**：分享"为什么这样做"的产品思维，以及每一步的心路历程
- **共同目标**：从零代码到业务赋能的完整闭环

### 互动时间

欢迎大家提问和交流！

---

## 附录：分享时间分配

- **开场（3分钟）**
- **第一部分：产品诞生背景（5分钟）**
- **第二部分：我们做了什么产品（5分钟）**
- **第三部分：产品功能演示（5分钟）**
- **第四部分：心路历程（27分钟）**
  - 第一阶段：从需求到想法验证（5分钟）
  - 第二阶段：打造MVP（6分钟）
  - 第三阶段：内部打磨（8分钟）
  - 第四阶段：产品化推广（8分钟）
- **总结与思考（2分钟）**

**总计：42分钟**

---

*文档创建时间：2025年1月*  
*文档版本：v2.0*
